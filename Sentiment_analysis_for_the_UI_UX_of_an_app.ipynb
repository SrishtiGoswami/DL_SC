{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQcYDNitAfz0x4qFNKTR/4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SrishtiGoswami/DL_SC/blob/main/Sentiment_analysis_for_the_UI_UX_of_an_app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "A6gL6jYxV377"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the dataset:** The first step is to load the user reviews dataset into a pandas DataFrame using the read_csv() function."
      ],
      "metadata": {
        "id": "Z2hIuwKHXEgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('dataset.csv')"
      ],
      "metadata": {
        "id": "frDCpoHTWXhL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split the data:** The next step is to split the dataset into training and testing sets using the sample() and drop() functions from pandas.\n",
        "\n",
        "This code randomly selects 80% of the rows from the dataset to be used for training, and the remaining 20% are used for testing."
      ],
      "metadata": {
        "id": "suv1MyqPXJuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = data.sample(frac=0.8, random_state=0)\n",
        "test_data = data.drop(train_data.index)"
      ],
      "metadata": {
        "id": "TCjwGKDaWeXp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocess the text data:** In order to use the text data in a machine learning model, we need to convert the text into numerical values. This is done using the Tokenizer and pad_sequences functions from Keras.\n",
        "\n",
        "The Tokenizer function converts each word in the text into an integer, and the pad_sequences function pads the sequences to a fixed length of 100."
      ],
      "metadata": {
        "id": "w75xCvIpXWj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(train_data['content'].values)\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(train_data['content'].values)\n",
        "train_padded = pad_sequences(train_sequences, maxlen=100, truncating='post')\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(test_data['content'].values)\n",
        "test_padded = pad_sequences(test_sequences, maxlen=100, truncating='post')"
      ],
      "metadata": {
        "id": "ouE6fJx8WhuE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the model architecture:** The next step is to define the architecture of the deep learning model. This code defines a simple model with an embedding layer, a global average pooling layer, and two dense layers.\n",
        "\n",
        "The embedding layer learns a dense vector representation for each word in the text, and the global average pooling layer aggregates these vectors into a fixed-length representation of the entire review. The dense layers then perform the actual classification task, with the final layer using a sigmoid activation function to output a probability between 0 and 1."
      ],
      "metadata": {
        "id": "4GxIVWiNXd4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(10000, 16, input_length=100),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n"
      ],
      "metadata": {
        "id": "BwqZ4QRoWroO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compile the model:** Once the model is defined, we need to compile it with a loss function, an optimizer, and any evaluation metrics we want to use.\n",
        "\n",
        "This code uses binary crossentropy loss, which is appropriate for binary classification problems, and the Adam optimizer, which is a popular optimization algorithm for deep learning models. We also specify that we want to track the accuracy metric during training."
      ],
      "metadata": {
        "id": "RIp-QZGPYByG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "irKiewZeX7Zk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the model:** The next step is to train the model on the training set using the fit() function.\n",
        "\n",
        "This code trains the model for 10 epochs and validates it on the testing set after each epoch. The fit() function returns a history object that contains information about the training process."
      ],
      "metadata": {
        "id": "-CBNsi2yYLPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(train_padded, train_data['sentiment'].values, epochs=10, \n",
        "                    validation_data=(test_padded, test_data['sentiment'].values))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWTPeQk_YJwY",
        "outputId": "d0812133-2bc3-4cc4-bc89-27ce105b23b3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1202/1202 [==============================] - 7s 5ms/step - loss: 0.3975 - accuracy: 0.8664 - val_loss: 0.3574 - val_accuracy: 0.8701\n",
            "Epoch 2/10\n",
            "1202/1202 [==============================] - 5s 4ms/step - loss: 0.2946 - accuracy: 0.8776 - val_loss: 0.2464 - val_accuracy: 0.8932\n",
            "Epoch 3/10\n",
            "1202/1202 [==============================] - 6s 5ms/step - loss: 0.2200 - accuracy: 0.9114 - val_loss: 0.2250 - val_accuracy: 0.9107\n",
            "Epoch 4/10\n",
            "1202/1202 [==============================] - 5s 4ms/step - loss: 0.1949 - accuracy: 0.9233 - val_loss: 0.2156 - val_accuracy: 0.9131\n",
            "Epoch 5/10\n",
            "1202/1202 [==============================] - 5s 4ms/step - loss: 0.1798 - accuracy: 0.9286 - val_loss: 0.2123 - val_accuracy: 0.9133\n",
            "Epoch 6/10\n",
            "1202/1202 [==============================] - 5s 4ms/step - loss: 0.1690 - accuracy: 0.9346 - val_loss: 0.2085 - val_accuracy: 0.9157\n",
            "Epoch 7/10\n",
            "1202/1202 [==============================] - 4s 4ms/step - loss: 0.1604 - accuracy: 0.9381 - val_loss: 0.2142 - val_accuracy: 0.9118\n",
            "Epoch 8/10\n",
            "1202/1202 [==============================] - 6s 5ms/step - loss: 0.1529 - accuracy: 0.9416 - val_loss: 0.2121 - val_accuracy: 0.9147\n",
            "Epoch 9/10\n",
            "1202/1202 [==============================] - 5s 4ms/step - loss: 0.1466 - accuracy: 0.9440 - val_loss: 0.2169 - val_accuracy: 0.9144\n",
            "Epoch 10/10\n",
            "1202/1202 [==============================] - 5s 4ms/step - loss: 0.1414 - accuracy: 0.9458 - val_loss: 0.2154 - val_accuracy: 0.9163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate the model:** Once the model is trained, we can evaluate its performance on the testing set using the evaluate() function."
      ],
      "metadata": {
        "id": "bCVHWtKFYXEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_padded, test_data['sentiment'].values, verbose=False)\n",
        "print(f'Test accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aRpbXsEWwje",
        "outputId": "2bb341f9-2eb0-45b7-c10c-966ee4cc6b33"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.9163458347320557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **new_reviews** variable is a list of two new reviews that we want to predict the sentiment of. In this case, one review is positive and the other is negative.\n",
        "\n",
        "The **texts_to_sequences** method of the tokenizer object is used to convert the text data in **new_reviews** to sequences of integers, which can be input to the neural network model.\n",
        "\n",
        "The **pad_sequences** function is used to ensure that all sequences are of the same length, which is necessary for input to the neural network. Here, we pad the sequences with zeros up to a maximum length of 100 and truncate any sequences that are longer than this.\n",
        "\n",
        "The **predict** method of the model object is used to generate predictions for the sentiment of the new reviews. The **new_padded** sequences are input to the model, which generates a prediction for each review.\n",
        "\n",
        "Finally, the predicted sentiment values for the new reviews are printed to the console. This line of code formats a string to include the predictions as a variable in the output."
      ],
      "metadata": {
        "id": "b7vOYhcWZEUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_reviews = ['The UI is very intuitive and easy to use.', 'The app is too slow and buggy.']\n",
        "new_sequences = tokenizer.texts_to_sequences(new_reviews)\n",
        "new_padded = pad_sequences(new_sequences, maxlen=100, truncating='post')\n",
        "predictions = model.predict(new_padded)\n",
        "\n",
        "print(f'Sentiment predictions: {predictions}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVI5uDc8W1zT",
        "outputId": "388ee470-af11-48ac-9b66-b402fbc472a9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n",
            "Sentiment predictions: [[0.99010366]\n",
            " [0.9840924 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This means that the model predicts a positive sentiment for the first review with a probability of 0.987, and a negative sentiment for the second review with a probability of 0.980."
      ],
      "metadata": {
        "id": "QuidLRFKZeMR"
      }
    }
  ]
}